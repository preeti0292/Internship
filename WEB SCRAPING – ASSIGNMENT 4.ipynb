{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf04a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all necessary imports for Beautiful Soup and Selenium library\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException\n",
    "import requests\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "import selenium \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9df8b",
   "metadata": {},
   "source": [
    "# Q1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "\n",
    "## #You need to find following details:\n",
    "* Rank\n",
    "* Name\n",
    "* Artist\n",
    "* Upload date\n",
    "* Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "172fede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING chrome driver exe\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\singh\\Downloads\\chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "#Opening the youtube page on automated webdriver\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03ff62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "#creating list for rank, uploader)name, video name, no of views, date of upload\n",
    "rank = []\n",
    "video_names = []\n",
    "video_uploader_name = []\n",
    "views = []\n",
    "upload_dates = []\n",
    "\n",
    "\n",
    "    #RANK ELEMENT\n",
    "try:\n",
    "    rank_obj = driver.find_elements(By.XPATH, '//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')[:30]\n",
    "    for i in rank_obj:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    rank.append('-')\n",
    "    \n",
    "    \n",
    "   #VIDEO NAME ELEMENT\n",
    "try:\n",
    "    videoname_obj = driver.find_elements(By.XPATH, '//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')[:30]\n",
    "    for i in videoname_obj:\n",
    "        video_names.append(i.text.split('[')[0][1:-1])\n",
    "except NoSuchElementException :\n",
    "    video_names.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #UPLOADER_OF_VIDEO\n",
    "try:\n",
    "    uploader_obj = driver.find_elements(By.XPATH, '//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')[:30]\n",
    "    for i in uploader_obj:\n",
    "        video_uploader_name.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    video_uploader_name.append('-')\n",
    "    \n",
    "    \n",
    "\n",
    "    #VIEWS ON THE VIDEOS\n",
    "try:\n",
    "    view_obj = driver.find_elements(By.XPATH, '//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')[:30]\n",
    "    for i in view_obj:\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    views.append('-')\n",
    "    \n",
    "#DATE OF THE VIDEO ELEMENT\n",
    "try:\n",
    "    date_obj = driver.find_elements(By.XPATH, '//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')[:30]\n",
    "    for i in date_obj:\n",
    "        upload_dates.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    upload_dates.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e1d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a diction of all the columns\n",
    "dict = {'Rank':rank, 'video_Name':video_names,'Artist':video_uploader_name,'Views in Billions':views,'Upload_Date':upload_dates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1a21e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING TABLE / DATA FRAME OF THE DICTIONARY\n",
    "table = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46dfdd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>video_Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views in Billions</th>\n",
       "      <th>Upload_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>11.40</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.98</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.47</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.81</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.64</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank            video_Name                                       Artist  \\\n",
       "0   1.      Baby Shark Dance  Pinkfong Baby Shark - Kids' Songs & Stories   \n",
       "1   2.             Despacito                                   Luis Fonsi   \n",
       "2   3.  Johny Johny Yes Papa                                  LooLoo Kids   \n",
       "3   4.          Shape of You                                   Ed Sheeran   \n",
       "4   5.         See You Again                                  Wiz Khalifa   \n",
       "\n",
       "  Views in Billions       Upload_Date  \n",
       "0             11.40     June 17, 2016  \n",
       "1              7.98  January 12, 2017  \n",
       "2              6.47   October 8, 2016  \n",
       "3              5.81  January 30, 2017  \n",
       "4              5.64     April 6, 2015  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997709d",
   "metadata": {},
   "source": [
    "# Q3 Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "\n",
    "You need to find following details:\n",
    "A) Name B) Description Note: - From guru99 home page you have to reach to selenium exception handling page through code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8137dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\singh\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "732e1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.guru99.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bcf66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "Name = []\n",
    "Description = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c88c23a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception_Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Exception_Name, Description]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clicking on Selenium button\n",
    "driver.find_element(By.XPATH,\"//li//a[@title='Selenium']\").click()\n",
    "\n",
    "# clicking on Exception Handling button\n",
    "driver.find_element(By.XPATH,'//a[@title=\"Selenium Exception Handling (Common Exceptions List)\"]').click()\n",
    "\n",
    "# scraping Name\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='table table-striped']/tbody/tr/td[1]\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "# scraping Description\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='table table-striped']/tbody/tr/td[2]\"):\n",
    "    Description.append(i.text)\n",
    "\n",
    "    \n",
    "# creating the dataframe from the scraped data\n",
    "Selenium = pd.DataFrame({})\n",
    "Selenium['Exception_Name'] = Name\n",
    "Selenium['Description'] = Description\n",
    "Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ebffa",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "\n",
    "Url = http://statisticstimes.com/ \n",
    "\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP at current price (19-20)\n",
    "D) GSDP at current price (18-19)\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3e79d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the specified url\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99d303de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on economy section\n",
    "economy = driver.find_element(By.XPATH, \"//div[@class='navbar']//div[2]//button\").click()\n",
    "\n",
    "urls = driver.find_element(By.XPATH, \"//div[@class='dropdown-content']//a[3]\")\n",
    "ineco_page = urls.get_attribute(\"href\")\n",
    "#Going to indian economy page\n",
    "driver.get(ineco_page)  \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "188556a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP_1 = []\n",
    "GSDP_2 = []\n",
    "Share = []\n",
    "GDP = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ec876b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the url of page containing GDP of indian states\n",
    "sta_GDP = driver.find_element(By.XPATH, \"//ul[@style='list-style-type:none;margin-left:20px;']/li/a\")\n",
    "GDP_url = sta_GDP.get_attribute(\"href\")\n",
    "\n",
    "driver.get(GDP_url)\n",
    "time.sleep(6)\n",
    "\n",
    "\n",
    "#Scraping data of rank\n",
    "for i in driver.find_elements(By.XPATH, \"//div[@id='table_id_wrapper']//tbody//tr//td[1]\"):\n",
    "    Rank.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of state name\n",
    "for i in driver.find_elements(By.XPATH, \"//div[@id='table_id_wrapper']//tbody//tr//td[2]\"):\n",
    "    State.append(i.text)\n",
    "\n",
    "    \n",
    "# Scraping data of GSDP at current price (19-20)\n",
    "for i in driver.find_elements(By.XPATH, \"//div[@id='table_id_wrapper']//tbody//tr//td[3]\"):\n",
    "    GSDP_1.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of GSDP at current price (18-19)\n",
    "for i in driver.find_elements(By.XPATH, \"//div[@id='table_id_wrapper']//tbody//tr//td[4]\"):\n",
    "    GSDP_2.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of Share(18-19)\n",
    "for i in driver.find_elements(By.XPATH, \"//div[@id='table_id_wrapper']//tbody//tr//td[5]\"):\n",
    "    Share.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of GDP($ billion)\n",
    "for i in driver.find_elements(By.XPATH, \"//div[@id='table_id_wrapper']//tbody//tr//td[6]\"):\n",
    "    GDP.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39716582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA FRAMEING\n",
    "StatisticsTime = pd.DataFrame({})\n",
    "StatisticsTime['Rank'] = Rank\n",
    "StatisticsTime['State'] = State\n",
    "StatisticsTime['GSDP at current price (19-20)'] = GSDP_1\n",
    "StatisticsTime['GSDP at current price (18-19)'] = GSDP_2\n",
    "StatisticsTime['Share(18-19)'] = Share\n",
    "StatisticsTime['GDP($ billion)'] = GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f57b4850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP at current price (19-20)</th>\n",
       "      <th>GSDP at current price (18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank          State GSDP at current price (19-20)  \\\n",
       "0    1    Maharashtra                             -   \n",
       "1    2     Tamil Nadu                     1,845,853   \n",
       "2    3  Uttar Pradesh                     1,687,818   \n",
       "3    4        Gujarat                             -   \n",
       "4    5      Karnataka                     1,631,977   \n",
       "\n",
       "  GSDP at current price (18-19) Share(18-19) GDP($ billion)  \n",
       "0                     2,632,792       13.94%        399.921  \n",
       "1                     1,630,208        8.63%        247.629  \n",
       "2                     1,584,764        8.39%        240.726  \n",
       "3                     1,502,899        7.96%        228.290  \n",
       "4                     1,493,127        7.91%        226.806  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the data frame\n",
    "StatisticsTime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe4ff8",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of trending repositories on Github.com. \n",
    "\n",
    "Url = https://github.com/ \n",
    "\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02cef19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the url\n",
    "driver.get(\"https://github.com/ \") # website from which we will scrape data\n",
    "\n",
    "# Selecting Trending option from from explore\n",
    "trending = driver.find_element(By.XPATH, \"/html/body/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a\").get_attribute(\"href\") \n",
    "driver.get(trending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde5c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "repo_urls1 = []\n",
    "rep_title1 = []\n",
    "Description1 = []\n",
    "Contributors1 = []\n",
    "Language1 = []\n",
    "lang1 = []\n",
    "\n",
    "#Fetching urls for each repository\n",
    "repository = driver.find_elements(By.XPATH, \"//h1[@class = 'h3 lh-condensed']//a\")\n",
    "for i in repository:\n",
    "    repo_urls1.append(i.get_attribute(\"href\"))\n",
    "\n",
    "    \n",
    "#Scraping data of repository title\n",
    "title = driver.find_elements(By.XPATH, \"//article[@class='Box-row']/h1/a\")\n",
    "for i in title:\n",
    "    rep_title1.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data from every repository page\n",
    "for i in repo_urls1:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "        \n",
    "    #Scraping data of decription\n",
    "    try:\n",
    "        desc = driver.find_element(By.XPATH, \"//div[@class='BorderGrid-cell']/p\")\n",
    "        Description1.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description1.append('-')\n",
    "    \n",
    "        \n",
    "    #Scraping data of contributors\n",
    "    try:\n",
    "        cont_tags = driver.find_element(By.XPATH, \"//*[contains(text(),'    Contributors ')]\")\n",
    "        Contributors1.append(cont_tags.text.replace('Contributors',''))\n",
    "    except NoSuchElementException:\n",
    "        Contributors1.append('-')\n",
    "        \n",
    "        \n",
    "    #fetching Languages used\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH, \"/html/body/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[6]/div/ul\"):\n",
    "            lang1.append(i.text)\n",
    "        Language1.append(lang1)\n",
    "    except NoSuchElementException:\n",
    "        Language1.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c416515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA FRAMING\n",
    "Github = pd.DataFrame({})\n",
    "Github['Repository title'] = rep_title1\n",
    "Github['Repository description'] = Description1\n",
    "Github['Contributors count'] = Contributors1\n",
    "Github['Language used'] = Language1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e73955dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebookincubator / AITemplate</td>\n",
       "      <td>AITemplate is a Python framework which renders...</td>\n",
       "      <td>6</td>\n",
       "      <td>[, Makefile\\n100.0%, C++\\n64.7%\\nPython\\n14.4%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>psf / black</td>\n",
       "      <td>The uncompromising Python code formatter</td>\n",
       "      <td>341</td>\n",
       "      <td>[, Makefile\\n100.0%, C++\\n64.7%\\nPython\\n14.4%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>snaplet / postgres-wasm</td>\n",
       "      <td>A PostgresQL server running in your browser</td>\n",
       "      <td>8</td>\n",
       "      <td>[, Makefile\\n100.0%, C++\\n64.7%\\nPython\\n14.4%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cryptogenic / PS5-4.03-Kernel-Exploit</td>\n",
       "      <td>An experimental webkit-based kernel exploit (A...</td>\n",
       "      <td>2</td>\n",
       "      <td>[, Makefile\\n100.0%, C++\\n64.7%\\nPython\\n14.4%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>folke / noice.nvim</td>\n",
       "      <td>ðŸ’¥ Highly experimental plugin that completely r...</td>\n",
       "      <td>2</td>\n",
       "      <td>[, Makefile\\n100.0%, C++\\n64.7%\\nPython\\n14.4%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Repository title  \\\n",
       "0         facebookincubator / AITemplate   \n",
       "1                            psf / black   \n",
       "2                snaplet / postgres-wasm   \n",
       "3  Cryptogenic / PS5-4.03-Kernel-Exploit   \n",
       "4                     folke / noice.nvim   \n",
       "\n",
       "                              Repository description Contributors count  \\\n",
       "0  AITemplate is a Python framework which renders...                  6   \n",
       "1           The uncompromising Python code formatter                341   \n",
       "2        A PostgresQL server running in your browser                  8   \n",
       "3  An experimental webkit-based kernel exploit (A...                  2   \n",
       "4  ðŸ’¥ Highly experimental plugin that completely r...                  2   \n",
       "\n",
       "                                       Language used  \n",
       "0  [, Makefile\\n100.0%, C++\\n64.7%\\nPython\\n14.4%...  \n",
       "1  [, Makefile\\n100.0%, C++\\n64.7%\\nPython\\n14.4%...  \n",
       "2  [, Makefile\\n100.0%, C++\\n64.7%\\nPython\\n14.4%...  \n",
       "3  [, Makefile\\n100.0%, C++\\n64.7%\\nPython\\n14.4%...  \n",
       "4  [, Makefile\\n100.0%, C++\\n64.7%\\nPython\\n14.4%...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Github.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5483b06",
   "metadata": {},
   "source": [
    "# Q 8 : Scrape the details of Highest selling novels.\n",
    "\n",
    "  Url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "  \n",
    "  You have to find the following details:\n",
    "  A) Book name\n",
    "  B) Author name\n",
    "  C) Volumes sold\n",
    "  D) Publisher\n",
    "  E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a7b0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the specified url\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d66cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Book_name = []\n",
    "Author = []\n",
    "Volumes_sold = []\n",
    "Publisher = []\n",
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fe7d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data of book names\n",
    "for i in driver.find_elements(By.XPATH, \"//tbody//tr/td[2]\"):\n",
    "    Book_name.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of author names\n",
    "for i in driver.find_elements(By.XPATH, \"//tbody/tr/td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Author.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Author.append('-')\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "#Scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH, \"//tbody/tr/td[4]\"):\n",
    "    Volumes_sold.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH, \"//tbody/tr/td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH, \"//tbody/tr/td[6]\"):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f9a75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA FRAMING\n",
    "Novel = pd.DataFrame({})\n",
    "Novel['Book Name'] = Book_name\n",
    "Novel['Author'] = Author\n",
    "Novel['Volume sold'] = Volumes_sold\n",
    "Novel['Publisher'] = Publisher\n",
    "Novel['Genre'] = Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84057ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing data frame\n",
    "Novel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df7eea4",
   "metadata": {},
   "source": [
    "# 9. Scrape the details most watched tv series of all time from imdb.com. \n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/ \n",
    "\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c066d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the specified url\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a9844109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists.\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fff61cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Names\n",
    "for i in driver.find_elements(By.XPATH, \"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of Year span\n",
    "for i in driver.find_elements(By.XPATH, \"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH, \"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of Run time\n",
    "for i in driver.find_elements(By.XPATH, \"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of Ratings\n",
    "for i in driver.find_elements(By.XPATH, \"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of votes\n",
    "for i in driver.find_elements(By.XPATH, \"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c60ccf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA FRAMING\n",
    "IMDB = pd.DataFrame({})\n",
    "IMDB['Name'] = Name\n",
    "IMDB['Year Span'] = Year_span\n",
    "IMDB['Genre'] = Genre\n",
    "IMDB['Run Time'] = Run_time\n",
    "IMDB['Ratings'] = Ratings\n",
    "IMDB['Votes'] = Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5ec4fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011â€“2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,061,713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016â€“ )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,155,207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010â€“2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>972,473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017â€“2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>289,927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014â€“ )</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>249,346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013â€“2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017â€“2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>60,749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005â€“2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>195,541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015â€“2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>238,188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011â€“2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016â€“ )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010â€“2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017â€“2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100     (2014â€“ )    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013â€“2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017â€“2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005â€“2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015â€“2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,061,713  \n",
       "1    51 min     8.7  1,155,207  \n",
       "2    44 min     8.1    972,473  \n",
       "3    60 min     7.5    289,927  \n",
       "4    43 min     7.6    249,346  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     49,693  \n",
       "96   50 min     7.8     60,749  \n",
       "97   42 min     8.1    195,541  \n",
       "98   45 min     7.1     41,155  \n",
       "99  572 min     8.6    238,188  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing data frame\n",
    "IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02775192",
   "metadata": {},
   "source": [
    "# 10. Details of Datasets from UCI machine learning repositories. \n",
    "\n",
    "Url = https://archive.ics.uci.edu/ \n",
    "\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c35100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the specified url\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79c07297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding view all dataset button\n",
    "view_dataset = driver.find_element(By.XPATH, \"//tbody[1]//tr/td[2]/span[2]/a\")    \n",
    "page_url = view_dataset.get_attribute(\"href\")\n",
    "driver.get(page_url)\n",
    "time.sleep(5)\n",
    "\n",
    "#Getting page urls containing list of all datasets\n",
    "all_lst = driver.find_element(By.XPATH, \"/html/body/table[2]/tbody/tr/td[2]/table[1]/tbody/tr/td[2]/p/a\")  \n",
    "lst_url = all_lst.get_attribute(\"href\")           \n",
    "driver.get(lst_url)\n",
    "time.sleep(5)\n",
    "\n",
    "#fetching url for each dataset\n",
    "data_url = driver.find_elements(By.XPATH, \"//p[@class='normal']//b/a\")    \n",
    "\n",
    "urls = []     \n",
    "for i in data_url:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "273d3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Data_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attr_type = []\n",
    "Instances = []\n",
    "n_attributes = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e9de5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping requiredinfo from urls\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    #Scraping Dataset name\n",
    "    try: \n",
    "        ds_name = driver.find_element(By.XPATH, \"//span[@class='heading']\")\n",
    "        Data_name.append(ds_name.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_name.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping data type\n",
    "    try:\n",
    "        dtype = driver.find_element(By.XPATH, \"//table[@border='1']//tbody/tr/td[2]\")\n",
    "        if dtype.text == \"N/A\": raise NoSuchElementException\n",
    "        Data_type.append(dtype.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping Attribute type\n",
    "    try:\n",
    "        atype = driver.find_element(By.XPATH, \"//table[@border='1']//tbody/tr[2]/td[2]\")\n",
    "        if atype.text == \"N/A\": raise NoSuchElementException\n",
    "        Attr_type.append(atype.text)\n",
    "    except NoSuchElementException:\n",
    "        Attr_type.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #scraping Task\n",
    "    try:\n",
    "        task = driver.find_element(By.XPATH, \"//table[@border='1']//tbody/tr[3]/td[2]\")\n",
    "        if task.text == \"N/A\": raise NoSuchElementException\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping No of instances\n",
    "    try:\n",
    "        inst = driver.find_element(By.XPATH, \"//table[@border='1']//tbody/tr/td[4]\")\n",
    "        if inst.text == \"N/A\": raise NoSuchElementException\n",
    "        Instances.append(inst.text)\n",
    "    except NoSuchElementException:\n",
    "        Instances.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping  No of attribute\n",
    "    try:\n",
    "        attr = driver.find_element(By.XPATH, \"//table[@border='1']//tbody/tr[2]/td[4]\")\n",
    "        if attr.text == \"N/A\": raise NoSuchElementException\n",
    "        n_attributes.append(attr.text)\n",
    "    except NoSuchElementException:\n",
    "        n_attributes.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #scraping year\n",
    "    try:\n",
    "        year = driver.find_element(By.XPATH, \"//table[@border='1']//tbody/tr[2]/td[6]\")\n",
    "        if year.text == \"N/A\": raise NoSuchElementException\n",
    "        Year.append(year.text[:4])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a929924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA FRAMING\n",
    "UCI = pd.DataFrame({})\n",
    "UCI['Data Name'] = Data_name\n",
    "UCI['Data Type'] = Data_type\n",
    "UCI['Task'] = Task\n",
    "UCI['Attribute type'] = Attr_type\n",
    "UCI['No of instance'] = Instances\n",
    "UCI['No of attributes'] = n_attributes\n",
    "UCI['Year'] = Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8eb6eaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instance</th>\n",
       "      <th>No of attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4 GHZ Indoor Channel Measurements Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>7840</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Road Network (North Jutland, Denmark) Data Set</td>\n",
       "      <td>Sequential, Text</td>\n",
       "      <td>Regression, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>434874</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3W dataset Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>1984</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9mers from cullpdb Data Set</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>158716</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Simulated Data set of Iraqi tourism places D...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>232</td>\n",
       "      <td>16</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Youtube cookery channels viewers comments in H...</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>9800</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>YouTube Multiview Video Games Dataset Data Set</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>120000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>YouTube Spam Collection Data Set</td>\n",
       "      <td>Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>1956</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Z-Alizadeh Sani Data Set</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>56</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Zoo Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>101</td>\n",
       "      <td>17</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Data Name  \\\n",
       "0         2.4 GHZ Indoor Channel Measurements Data Set   \n",
       "1    3D Road Network (North Jutland, Denmark) Data Set   \n",
       "2                                  3W dataset Data Set   \n",
       "3                          9mers from cullpdb Data Set   \n",
       "4    : Simulated Data set of Iraqi tourism places D...   \n",
       "..                                                 ...   \n",
       "617  Youtube cookery channels viewers comments in H...   \n",
       "618     YouTube Multiview Video Games Dataset Data Set   \n",
       "619                   YouTube Spam Collection Data Set   \n",
       "620                           Z-Alizadeh Sani Data Set   \n",
       "621                                       Zoo Data Set   \n",
       "\n",
       "                     Data Type                        Task  \\\n",
       "0                 Multivariate              Classification   \n",
       "1             Sequential, Text      Regression, Clustering   \n",
       "2    Multivariate, Time-Series  Classification, Clustering   \n",
       "3                   Sequential  Classification, Regression   \n",
       "4                 Multivariate  Classification, Clustering   \n",
       "..                         ...                         ...   \n",
       "617         Multivariate, Text              Classification   \n",
       "618         Multivariate, Text  Classification, Clustering   \n",
       "619                       Text              Classification   \n",
       "620                          -              Classification   \n",
       "621               Multivariate              Classification   \n",
       "\n",
       "           Attribute type No of instance No of attributes  Year  \n",
       "0                    Real           7840                5  2018  \n",
       "1                    Real         434874                4  2013  \n",
       "2           Integer, Real           1984                8  2019  \n",
       "3                    Real         158716                4  2021  \n",
       "4                       -            232               16  2020  \n",
       "..                    ...            ...              ...   ...  \n",
       "617                     -           9800                3  2019  \n",
       "618         Integer, Real         120000          1000000  2013  \n",
       "619                     -           1956                5  2017  \n",
       "620         Integer, Real            303               56  2017  \n",
       "621  Categorical, Integer            101               17  1990  \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing dataframe\n",
    "UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56de9c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
